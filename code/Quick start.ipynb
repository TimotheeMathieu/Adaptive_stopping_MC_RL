{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b53ab0-99e8-40e8-ad2c-f84723696884",
   "metadata": {},
   "source": [
    "# Adaptive stopping in a Bandit problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254a3413-ec29-4e2b-83a9-2e0177582449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from compare_agents import MultipleAgentsComparator, Two_AgentsComparator\n",
    "\n",
    "from rlberry.agents.torch import DQNAgent, PPOAgent, A2CAgent\n",
    "from rlberry.agents import RSUCBVIAgent\n",
    "import pandas as pd\n",
    "\n",
    "from rlberry.envs.bandits import BernoulliBandit\n",
    "from rlberry.wrappers import WriterWrapper\n",
    "from rlberry.agents.bandits import (\n",
    "    IndexAgent,\n",
    "    RandomizedAgent,\n",
    "    makeBoundedIMEDIndex,\n",
    "    makeBoundedMOSSIndex,\n",
    "    makeBoundedNPTSIndex,\n",
    "    makeBoundedUCBIndex,\n",
    "    makeBoundedUCBVIndex,\n",
    "    makeETCIndex,\n",
    "    makeEXP3Index,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e8ffef-f39e-40fc-9ecc-7b3f1c191dde",
   "metadata": {},
   "source": [
    "We wish to reproduce the results in https://rlberry.readthedocs.io/en/latest/auto_examples/demo_bandits/plot_compare_index_bandits.html#sphx-glr-auto-examples-demo-bandits-plot-compare-index-bandits-py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c110ecb9-a0f8-4e15-986b-3942fb7b72d6",
   "metadata": {},
   "source": [
    "## Problem setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc54b6bb-277b-49be-b629-93593f983739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of the problem\n",
    "means = np.array([0.6, 0.6, 0.6, 0.9])  # means of the arms\n",
    "A = len(means)\n",
    "T = 2000  # Horizon\n",
    "M = 10  # number of MC simu\n",
    "\n",
    "# Construction of the experiment\n",
    "\n",
    "env_ctor = BernoulliBandit\n",
    "env_kwargs = {\"p\": means}\n",
    "\n",
    "\n",
    "class UCBAgent(IndexAgent):\n",
    "    name = \"UCB\"\n",
    "\n",
    "    def __init__(self, env, **kwargs):\n",
    "        index, _ = makeBoundedUCBIndex()\n",
    "        IndexAgent.__init__(self, env, index, **kwargs)\n",
    "        self.env = WriterWrapper(\n",
    "            self.env, self.writer, write_scalar=\"reward\"\n",
    "        )\n",
    "class ETCAgent(IndexAgent):\n",
    "    name = \"ETC\"\n",
    "\n",
    "    def __init__(self, env, m=20, **kwargs):\n",
    "        index, _ = makeETCIndex(A, m)\n",
    "        IndexAgent.__init__(self, env, index, **kwargs)\n",
    "        self.env = WriterWrapper(\n",
    "            self.env, self.writer, write_scalar=\"reward\"\n",
    "        )\n",
    "\n",
    "\n",
    "class IMEDAgent(IndexAgent):\n",
    "    name = \"IMED\"\n",
    "\n",
    "    def __init__(self, env, **kwargs):\n",
    "        index, tracker_params = makeBoundedIMEDIndex()\n",
    "        IndexAgent.__init__(self, env, index, tracker_params=tracker_params, **kwargs)\n",
    "        self.env = WriterWrapper(\n",
    "            self.env, self.writer, write_scalar=\"reward\"\n",
    "        )\n",
    "\n",
    "class NPTSAgent(IndexAgent):\n",
    "    name = \"NPTS\"\n",
    "\n",
    "    def __init__(self, env, **kwargs):\n",
    "        index, tracker_params = makeBoundedNPTSIndex()\n",
    "        IndexAgent.__init__(self, env, index, tracker_params=tracker_params, **kwargs)\n",
    "        self.env = WriterWrapper(\n",
    "            self.env, self.writer, write_scalar=\"reward\"\n",
    "        )\n",
    "\n",
    "\n",
    "Agents_class = [\n",
    "    ETCAgent,\n",
    "    IMEDAgent,\n",
    "    NPTSAgent,\n",
    "    UCBAgent,\n",
    "]\n",
    "\n",
    "managers = [\n",
    "    (Agent,\n",
    "        dict(\n",
    "        train_env=(env_ctor, env_kwargs),\n",
    "        fit_budget=T,\n",
    "        parallelization=\"process\",\n",
    "        mp_context=\"fork\")\n",
    "    )\n",
    "    for Agent in Agents_class\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92802c6d-df0a-4dff-bb8d-b828df82446e",
   "metadata": {},
   "source": [
    "## Adastop algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f442840-1bc3-41fc-aa65-d2f5a1788e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to be able to see a difference of 5 and the std is around 10\n",
    "n = 10\n",
    "K = 10\n",
    "B=100000\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85ad8d80-ca78-4c1e-9c74-555aa84d9f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100000/100000 [00:08<00:00, 12357.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected power is 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_managers = len(managers)\n",
    "\n",
    "comparator  = Two_AgentsComparator(n=n, K=K, B=B, alpha=alpha / (n_managers*(n_managers-1)/2), n_evaluations = 100)\n",
    "print(\"Expected power is\", comparator.power(M=100000, mup=0, muq = 20, sigmap=15, sigmaq=15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca26cf10-8efc-46f1-bf16-719226806f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With these parameters, we have a maximum of 100 fits done for each agent\n",
      "Number of comparisons is 6.0\n"
     ]
    }
   ],
   "source": [
    "print('With these parameters, we have a maximum of {} fits done for each agent'.format(n*K))\n",
    "print('Number of comparisons is {}'.format(n_managers*(n_managers-1)/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49d7997-f185-4783-8587-c02745cdb3cb",
   "metadata": {},
   "source": [
    "let us now compare all the different algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41961fa4-8ee8-450d-8863-48f29affe506",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rlberry.utils.logging import set_level\n",
    "set_level('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57995129-0d68-4b8e-a21b-b434df3eb3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparator(MultipleAgentsComparator):\n",
    "    def __init__(self, **kwargs):\n",
    "        MultipleAgentsComparator.__init__(self, **kwargs)\n",
    "        \n",
    "    def _get_evals(self, manager):\n",
    "        \"\"\"\n",
    "        Compute the cumulative reward\n",
    "        \"\"\"\n",
    "        eval_values = []\n",
    "        for idx in  manager.get_writer_data():\n",
    "            df = manager.get_writer_data()[idx]\n",
    "            eval_values.append(-np.sum(np.max(means)-df.loc[df['tag']=='reward', 'value']))\n",
    "        return eval_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24bf254e-bc94-4d9c-aa58-e3ac7ea53a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Step 1\n",
      "Step 2\n",
      "Step 3\n",
      "Step 4\n",
      "Step 5\n",
      "Step 6\n",
      "Step 7\n",
      "Step 8\n",
      "Step 9\n",
      "['accept' 'accept' 'reject' 'accept' 'reject' 'reject'] [[0 1]\n",
      " [0 2]\n",
      " [0 3]\n",
      " [1 2]\n",
      " [1 3]\n",
      " [2 3]] [array([2, 3]), array([1, 3]), array([0, 3])]\n"
     ]
    }
   ],
   "source": [
    "comparator  = Comparator(n=n, K=K, B=B, alpha=alpha, n_evaluations = 100)\n",
    "\n",
    "comparator.compare(managers)\n",
    "\n",
    "print(comparator.decisions,\n",
    "      comparator.comparisons,\n",
    "      comparator.rejected_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "701b3d5e-c6a6-4765-a433-11aa8c6fa0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(comparator.eval_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cff6b641-f43e-4d57-8a00-e34f7a26799d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-14.85 -15.71 -13.86 -40.63]\n"
     ]
    }
   ],
   "source": [
    "print(comparator.mean_eval_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db68018-404b-4c34-b996-113f97cc0334",
   "metadata": {},
   "source": [
    "The rejected comparisons are the comparisons with the last algo (UCB) which is to be expected as UCB performs considerably worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0b2d00-4ea7-4536-bac6-27e5dfaa9d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
